{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e9f1d5-5f19-464c-bb3a-d855db2b2904",
   "metadata": {},
   "source": [
    "## Tutorial 1: reading and preparing data for an HsM model\n",
    "\n",
    "In this tutorial we will show you how to read data from :\n",
    "\n",
    "1. Raw (preprocessed) EEG data in *.bdf* or *.fif* format\n",
    "2. Data already transformed to PC space (e.g. previous applications of HsMM MVPA)\n",
    "3. Read epoched data [to be written]\n",
    "\n",
    "All these methods assume that the data has been preprocessed (e.g. see method section of [this paper](https://psyarxiv.com/nmg6w/)  for an example of preprocessing for HsMM-MVPA), if you don't know where to start for preprocessing EEG, the [MNE](https://mne.tools/stable/index.html) is full of tutorials on EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc7eb02-6f3d-4caa-812e-af230f302370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Development only\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/gweindel/owncloud/projects/RUGUU/hsmm-mvpy/src\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de89105-f9e4-4e28-a7ad-c332396f100f",
   "metadata": {},
   "source": [
    "# 1. Reading raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6355d7-1820-4343-a8c0-0955545964de",
   "metadata": {},
   "source": [
    "For the following I give an example using (yet not public) preprocessed EEG data that has not yet been epoched.\n",
    "\n",
    "First in order for the HsMM to run on each trial we have to declare the stimulus triggers as well as the response triggers which defines a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54903f1d-4068-462c-a8b6-2740de486f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = {'accuracy/left/1':211,'accuracy/left/2':212,'accuracy/left/3':213,\n",
    "           'accuracy/right/1':221,'accuracy/right/2':222,'accuracy/right/3':223,\n",
    "            'speed/left/1':111,'speed/left/2':112,'speed/left/3':113, #conditions in the experiment\n",
    "           'speed/right/1':121,'speed/right/2':122,'speed/right/3':123} # used for segmentation\n",
    "resp_id = {'r_left':100,'r_right':200}#Response events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723057a-bd00-4a1c-9756-785daed5547f",
   "metadata": {},
   "source": [
    "Then we specify wich files we want to analyse, if for example you have all your participant dat inside one folder you can do the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b337fd68-265b-4a6a-a482-c5382e7e42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "eeg_path = '../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/'#Where the data is relative to where you run the code on your computer\n",
    "subj_names = [x.split('_')[1].split('.')[0] for x in os.listdir(eeg_path) if 'preprocessed' in x]#select files which contain the string 'preprocessed'\n",
    "subj_files = [eeg_path+ 'preprocessed_'+x+'_raw.fif' for x in subj_names]#Create a list of files that can be read from the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db151cd-c139-4a81-9655-56ac8bf9b4cc",
   "metadata": {},
   "source": [
    "Next we can directly use the ```subj_file``` list and feed it to the ```hsmm.utils.read_mne_EEG``` but first you have to decide on a number of parameters regarding EEG processing, see the following helper of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea297de-5a50-4f92-ab0a-4c7aa1d8ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mne_EEG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mevent_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresp_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubj_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mevents_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moffset_after_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhigh_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlow_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mupper_limit_RT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlower_limit_RT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreject_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Reads EEG data format (.fif or .bdf) using MNE's integrated function .\n",
       "\n",
       "Notes: \n",
       "- Only EEG data are selected (other channel types are discarded)\n",
       "- All times are expressed on the second scale.\n",
       "- If multiple files in pfiles the data of the group is read and seqentially processed.\n",
       "- Reaction Times are only computed if response trigger is in the epoch window (determined by tmin and tmax)\n",
       "\n",
       "Procedure:\n",
       "1) the data is filtered with filters specified in low_pass and high_pass. Parameters of the filter are\n",
       "    determined by MNE's filter function.\n",
       "2) if no events is provided, detect events in stumulus channel and keep events with id in event_id and resp_id.\n",
       "3) eventual downsampling is performed if sfreq is lower than the data's sampling frequency. The event structure is\n",
       "    passed at the resample() function of MNE to ensure that events are approriately timed after downsampling.\n",
       "4) epochs are created based on stimulus onsets (event_id) and tmin and tmax. Epoching removes any epoch where a \n",
       "    'BAD' annotiation is present and all epochs where an electrode exceeds reject_threshold. Epochs are baseline \n",
       "    corrected from tmin to stimulus onset (time 0).\n",
       "5) Reaction times (RT) are computed based on the sample difference between onset of stimulus and response triggers. \n",
       "    If no response event happens after a stimulus or if RT > upper_limit_RT & < upper_limit_RT, RT is 0.\n",
       "6) all the non-rejected epochs with positive RTs are cropped to stimulus onset to stimulus_onset + RT.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "pfiles : str or list\n",
       "    list of EEG files to read\n",
       "event_id : dict\n",
       "    Dictionary containing the correspondance of named condition [keys] and event code [values]\n",
       "resp_id : ndarray\n",
       "    Dictionary containing the correspondance of named response [keys] and event code [values]\n",
       "sfreq : float\n",
       "    Desired sampling frequency\n",
       "subj_idx : list\n",
       "    List of subject names\n",
       "events_provided : float\n",
       "    np.array with 3 columns -> [samples of the event, initial value of the channel, event code]. To use if the\n",
       "    automated event detection method of MNE is not appropriate \n",
       "verbose : bool\n",
       "    Whether to display MNE's message\n",
       "tmin : float\n",
       "    Time taken before stimulus onset to compute baseline\n",
       "tmax : float\n",
       "    Time taken after stimulus onset\n",
       "offset_after_resp : float\n",
       "    Time taken after onset of the response\n",
       "low_pass : float\n",
       "    Value of the low pass filter\n",
       "high_pass : float\n",
       "    Value of the high pass filter\n",
       "upper_limit_RT : float\n",
       "    Upper limit for RTs. Longer RTs are discarded\n",
       "lower_limit_RT : float\n",
       "    Lower limit for RTs. Shorter RTs are discarded\n",
       "reject_threshold : float\n",
       "    Rejection threshold to apply when creating epochs, expressed in microvolt\n",
       "\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "epoch_data : xarray\n",
       "    Returns an xarray Dataset with all the data, events, electrodes, participant. \n",
       "    All eventual participant/electrodes naming and epochs index are kept. \n",
       "    The choosen sampling frequnecy is stored as attribute.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/owncloud/projects/RUGUU/hsmm-mvpy/src/hsmm_mvpy/utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hsmm_mvpy import utils\n",
    "utils.read_mne_EEG?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9ca76-d779-440c-bf42-06544a3b8d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant ../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/preprocessed_S10_raw.fif\n",
      "Reading 0 ... 4814847  =      0.000 ...  4701.999 secs...\n",
      "Downsampling to 100 Hz\n",
      "N trials without response event: 0\n",
      "Applying reaction time trim to keep RTs between 0.25 and 2 seconds\n",
      "2294 RTs kept of 2294 clean epochs\n",
      "2269 trials were retained for participant ../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/preprocessed_S10_raw.fif\n",
      "End sampling frequency is 100 Hz\n",
      "Processing participant ../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/preprocessed_S18_raw.fif\n",
      "Reading 0 ... 5106687  =      0.000 ...  4986.999 secs...\n",
      "Downsampling to 100 Hz\n",
      "N trials without response event: 0\n",
      "Applying reaction time trim to keep RTs between 0.25 and 2 seconds\n",
      "2355 RTs kept of 2355 clean epochs\n",
      "2349 trials were retained for participant ../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/preprocessed_S18_raw.fif\n",
      "End sampling frequency is 100 Hz\n",
      "Processing participant ../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/preprocessed_S12_raw.fif\n",
      "Reading 0 ... 5602303  =      0.000 ...  5470.999 secs...\n",
      "Downsampling to 100 Hz\n",
      "N trials without response event: 0\n",
      "Applying reaction time trim to keep RTs between 0.25 and 2 seconds\n",
      "2377 RTs kept of 2377 clean epochs\n",
      "2364 trials were retained for participant ../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/preprocessed_S12_raw.fif\n",
      "End sampling frequency is 100 Hz\n",
      "Processing participant ../../../PHD/ForceEEG_2021/processing_EEG/preprocessed_data/preprocessed_S7_raw.fif\n",
      "Reading 0 ... 4881407  =      0.000 ...  4766.999 secs...\n"
     ]
    }
   ],
   "source": [
    "import hsmm_mvpy as hsmm\n",
    "sfreq = 100 #at what sampling rate we want the data, downsampling to 100Hz is computationally less intensive \n",
    "tmin, tmax = -.25, 2 #window size for the epochs, from 250ms before the stimulus up to 2 seconds after\n",
    "offset_after_resp = .05 #The epochs will be cropped to each epochs RTs, but we want to keep a few ms after the response in case some bumps are later\n",
    "high_pass, low_pass = .5,  30 #The filtering bandwidth\n",
    "lower_limit_RT, upper_limit_RT = .25, 2 #lower and upper limit for the RTs all values outside of this range are discarded\n",
    "\n",
    "mne_data = hsmm.utils.read_mne_EEG(subj_files, event_id, resp_id, sfreq, subj_idx=subj_names, tmin=tmin, tmax=tmax, offset_after_resp=offset_after_resp, \n",
    "                            high_pass=high_pass, low_pass =low_pass, lower_limit_RT=lower_limit_RT, upper_limit_RT=upper_limit_RT, \n",
    "                            verbose=False)#Turning verbose off for the documentation but it is recommended to leave it on as some output from MNE might be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56aa6d5-9726-47af-a29f-8039c370eea6",
   "metadata": {},
   "source": [
    "And finally to keep track of sensor location we just mount the appropriate defaul layout for the future topologies we are going to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa370c-2413-471b-8fe1-efc1bd862210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne \n",
    "raw = mne.io.read_raw_fif(subj_files[0], preload=False, verbose=False)#loading for sensor position\n",
    "raw.set_montage(mne.channels.make_standard_montage('biosemi64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83141b98-5bad-4c27-a016-3ef44baa2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.channels.make_standard_montage('biosemi64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109cdef0-bf05-4cd2-a218-3514ec3a886c",
   "metadata": {},
   "source": [
    "We save the data to use it in tutorial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb87ad-6424-4ab2-a9a8-136ef1ec1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.to_netcdf('mne_data_demo.nc')#saving the epoched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2e305-396b-400e-8b7c-0d973c36c29c",
   "metadata": {},
   "source": [
    "# 2. Data already transformed to PC space (e.g. previous applications of HsMM MVPA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262f14a-6996-4b46-a096-65138861b8e7",
   "metadata": {},
   "source": [
    "This part is addressed mainly for researchers wanting to replicate previous findings with matlab with data that has already been turned into principal component space.\n",
    "\n",
    "For this example we will use the data from the study by Anderson, Zhang, Borst, & Walsh ([2016](https://psycnet.apa.org/doi/10.1037/rev0000030)) that you can download here: http://www.ai.rug.nl/~jpborst/modelbasedneuro/analysis_data_model.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b099a8-1db9-4163-b4cb-dd690a95ed7d",
   "metadata": {},
   "source": [
    "First we read the .mat data file using ```scipy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67599250-4a83-48ab-a62a-978491690f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "mat = scipy.io.loadmat('../matlab/analysis_data_model/data/varForBumps135_100.mat')#Where the .mat file with all the data and necessary infos is\n",
    "data = np.array(mat['normedscore10'])# The data in PC space\n",
    "starts = np.array(mat['x'][:,0]) -1#correcting to be 0 indexed\n",
    "ends = np.array(mat['y'][:,0])-1#correcting to be 0 indexed\n",
    "subjects = np.array(mat['subjects'])-1 #correcting to be 0 indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7111477-2397-41e9-aa48-aaf8384db7b4",
   "metadata": {},
   "source": [
    "Here we will adapt the structure of the matlab data to the expected data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2cce3c-bffe-4713-9db8-530ef6a1d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recovering RTs, trials and participants\n",
    "durations = ends - starts + 1\n",
    "limits = np.cumsum(durations)\n",
    "limits = np.concatenate([[0],limits])\n",
    "participant, trials = np.unique(subjects, return_counts=True)\n",
    "\n",
    "\n",
    "# creating data watrix with participant x trial x max duration x electrodes/comp\n",
    "unstacked_data = np.tile(np.nan, (len(participant), np.max(trials), np.shape(data)[1], np.max(durations)))\n",
    "conditions = np.tile(np.nan, (len(participant), np.max(trials)))\n",
    "for trial in np.arange(len(durations)):\n",
    "    if trial > 0 and subjects[trial] == subjects[trial-1]:\n",
    "        within_trial += 1\n",
    "    else:\n",
    "        within_trial = 0\n",
    "    unstacked_data[subjects[trial], within_trial, :,:durations[trial],] = data[limits[trial]:limits[trial+1]].T\n",
    "    conditions[subjects[trial], within_trial] = mat['conds'][trial]\n",
    "\n",
    "unstacked_data = hsmm.utils.hsmm_data_format(unstacked_data, conditions, sfreq=100, participants=participant)#converting to xarray\n",
    "unstacked_data = unstacked_data.rename({'electrodes':'component'})#Data is already on PC space so no need to use the transform function\n",
    "unstacked_data.to_netcdf('unstacked_data.nc')#saving the converted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885603a-68ca-4658-808d-b2defe2e8f9d",
   "metadata": {},
   "source": [
    "Now the data is in the expected format for HsMM_MVpy however we still need to recover the electrodes position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd96cbe-1ea2-441c-8ebc-b5b764e0bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_loc = scipy.io.loadmat('../matlab/analysis_data_model/analysis/HSMM_code/chanlocs.mat')#Channel location \n",
    "positions_dict_i =  [{str(electrode[0][0]):[-electrode[5][0][0]/1000,electrode[4][0][0]/1000,electrode[6][0][0]/1000]} \n",
    "                     for electrode in channels_loc['chanlocs'][0]]#Dictionnary with x,y,z positions\n",
    "positions_dict = {}\n",
    "for i in positions_dict_i:\n",
    "     positions_dict.update(i)\n",
    "        \n",
    "from mne import channels#\n",
    "\n",
    "montage = channels.make_dig_montage(positions_dict,coord_frame='head')\n",
    "positions = np.array([x[-1][:2] for x in np.array(list(montage.get_positions()['ch_pos'].items()),dtype=object)[:,:]])\n",
    "names = np.array([x[0] for x in np.array(list(montage.get_positions()['ch_pos'].items()),dtype=object)[:,:]])\n",
    "montage.plot();\n",
    "np.save('positions',positions)#saving the positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a810e7b-b236-42e6-93ce-e4aee954ffdb",
   "metadata": {},
   "source": [
    "Everything is now ready to be used in hsmm_mvpy, e.g. see tutorial 3 that uses the data we just extracted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
